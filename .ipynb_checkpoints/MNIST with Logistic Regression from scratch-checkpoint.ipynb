{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python implementation of Logistic Regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Umberto Michelucci, um@udata.science_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I develop a complete version of Logistic Regression from scratch, without using any library (except numpy). I apply the model to a subset of MNIST data containing only the digits 1 and 2 (see the data preparation part to see how to do it) to do binary classification. For the equations and the mathematics behind the python code you can refer (to this notebook)[http://localhost:8888/notebooks/Documents/Data%20Science/Projects/Logistic-Regression-Explained/Logistic%20Regression%20from%20scratch.ipynb#] where I did a complete derivation of the mathematics behind the model. The relevant equations are reported here to make it easier for the reader to follow the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: the formulas are not explained or derived and are reported only to help the reader follow the Python code. For a derivation and justification please refer to the notebook above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get MNIST data we use the function fetch_mldata, in the datasets package. Let's get all the dataset, and then we will select only the digits we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([ 0.,  0.,  0., ...,  9.,  9.,  9.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know how many digits we have we can run this simple code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit 0 appear 6903 times\n",
      "digit 1 appear 7877 times\n",
      "digit 2 appear 6990 times\n",
      "digit 3 appear 7141 times\n",
      "digit 4 appear 6824 times\n",
      "digit 5 appear 6313 times\n",
      "digit 6 appear 6876 times\n",
      "digit 7 appear 7293 times\n",
      "digit 8 appear 6825 times\n",
      "digit 9 appear 6958 times\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(10):\n",
    "    print (\"digit\", i, \"appear\", np.count_nonzero(y == i), \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: datasets loaded by scikit-learn have a dictionary structure. \n",
    "\n",
    "- a DESCR structure describing the dataset\n",
    "- a ```data``` key containing an array with one row per instance and one column per feature\n",
    "- a ```target``` with an array with the labels\n",
    "\n",
    "we have 70000 digits available, from 0 to 9. Let's define a helper function that will allow us to visualize the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b974d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digit(some_digit):\n",
    "    \n",
    "    some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "    plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_digit(X[36003])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the relative label..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36003]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test set preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first reduce our dataset only to 1 and 2 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_12 = X[np.any([y == 1,y == 2], axis = 0)]\n",
    "y_12 = y[np.any([y == 1,y == 2], axis = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a couple of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCR8CCR8CCR8CCR8C/Q+8MTpbTZpLjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bd34630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABkZJREFUeJzt3b9vTX8cx/FeEYNIroGBhclAYhGDRK9OBtzJSCQiBpsw\nshGLwY/YBP+ADk2HppO0VpFIRGI1SOigBnO/g0Xi5n2+de/pvb2vx2P0inuO6DNn+PTe29nY2JgB\nsuwY9w0AW0/4EEj4EEj4EEj4EEj4EEj4EGjnFlzDLwrA+HQG/aEnPgQSPgQSPgQSPgQSPgQSPgQS\nPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQS\nPgQSPgQSPgQSPgQSPgTaiq/JZoKtrKyU+9zcXLl3OgO/hXlker1euS8sLJR7t9sd5e1MDU98CCR8\nCCR8CCR8CCR8CCR8CCR8CNTZ2Nho+xqtXyDZ2tpauV+/fr3cV1dXy319fb3c2z7Hb/r5bDrH7/f7\no7yd7Wjgf5AnPgQSPgQSPgQSPgQSPgQSPgQSPgRyjj/hms6pHzx4UO7v3r0b6vpNPx/jPsc/f/58\nuS8uLo7ydrYj5/jAb8KHQMKHQMKHQMKHQMKHQMKHQD5Xf8J9+fKl3Ic9px/WsWPHyr3pHP7Tp0+j\nvB3+J098CCR8CCR8CCR8CCR8CCR8CCR8COQcf8yazrnfvn071Ovv3bu33K9cuVLujx49KvelpaVy\nv3DhQrkzHp74EEj4EEj4EEj4EEj4EEj4EEj4EMg5/oQ7evRouc/Pz5f7kydPyv3y5cubvqc/3bt3\nb6i/P6y7d++O9frblSc+BBI+BBI+BBI+BBI+BBI+BBI+BHKOP2ZN3y9/9erVcj916lS5nzhxYtP3\n9KcXL16U+8ePH4d6/SZNnydw4MCBVq8/rTzxIZDwIZDwIZDwIZDwIZDwIZDwIVCn6XPdR6D1C9Ce\nHTvqZ0PT7yEM682bN+Xe6/Vavf4UGPgf5IkPgYQPgYQPgYQPgYQPgYQPgYQPgbwff8otLCyU++PH\nj8u97d/zePr0abk7p2+HJz4EEj4EEj4EEj4EEj4EEj4EEj4E8n78KXfu3LlyX15eLvemn4+m9+Mf\nPny43N+/f1/u3W633Gnk/fjAb8KHQMKHQMKHQMKHQMKHQMKHQN6Pv80tLS2Ve9M5+bBOnjxZ7g8f\nPix35/Tj4YkPgYQPgYQPgYQPgYQPgYQPgYQPgZzjT7iVlZVyv3TpUrn//PlzlLfzl/3795f77Oxs\nq9fn33jiQyDhQyDhQyDhQyDhQyDhQyDhQyDn+GPW9Ln1z549K/f19fVR3s5fjh8/Xu6vXr1q9fq0\nwxMfAgkfAgkfAgkfAgkfAgkfAgkfAnWazpFHoPULTLJfv36V+82bN8v95cuXo7ydTfv27Vu579u3\nb4vuhH/UGfSHnvgQSPgQSPgQSPgQSPgQSPgQSPgQyPvxW/b169dyb/ucfteuXeV++/btch/3OX3T\n5w2sra0Ntd+/f7/c+/1+ud+4caPcJ5UnPgQSPgQSPgQSPgQSPgQSPgQSPgRyjj/ldu/eXe5nz54d\n6vVfv35d7k3n6J8/fy73Dx8+lPvq6mq5D+vIkSOtvv64eOJDIOFDIOFDIOFDIOFDIOFDIOFDIOf4\nY9b29xr8+PGj3Ofm5sq96f46nYEf2z4ybV//zJkz5X769OmhXn9SeeJDIOFDIOFDIOFDIOFDIOFD\nIOFDIOf4Y9b2OXjbxn3/Tb+HcOvWrXKfnZ0t9263u9lb2hY88SGQ8CGQ8CGQ8CGQ8CGQ8CGQ8CGQ\nc/yWHTx4sNyvXbtW7ouLi+X+/fv3Td/TKO3Zs6fcm/79Fy9eLPem98P3er1yb/pegVSe+BBI+BBI\n+BBI+BBI+BBI+BBI+BCo0/bnus/MzLR+gWnW9P3wz58/L/f5+flyv3Pnzqbv6U+HDh0q936/P9Tr\nM7SBH5jgiQ+BhA+BhA+BhA+BhA+BhA+BhA+BnOPDdHOOD/wmfAgkfAgkfAgkfAgkfAgkfAgkfAgk\nfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgkfAgk\nfAgkfAgkfAgkfAi0cwuuMfD7uYHx8cSHQMKHQMKHQMKHQMKHQMKHQMKHQMKHQMKHQMKHQMKHQMKH\nQMKHQMKHQMKHQMKHQMKHQMKHQMKHQMKHQP8B8v/k4gtFDx4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c227748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABY5JREFUeJzt3bFLlW0cxvH3vNQQhENDIUG5CB1w0xIcoknoDxCxlhpq\nbiraa9BFEKfAwd0/IAuCQtprCVokkKAxEEMaTkPreX8P9fB43uP1+YxdcO6zfLmH20O9wWDwD5Dl\n31F/AeDkCR8CCR8CCR8CCR8CCR8CCR8CnTmBM/yhAIxOb9g/uvEhkPAhkPAhkPAhkPAhkPAhkPAh\nkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAhkPAh\nkPAhkPAhkPAhkPAh0En8N9nQmZs3b5b73t5eud+/f7/ct7a2/vg7jQM3PgQSPgQSPgQSPgQSPgQS\nPgQSPgTyjs//2ocPH8p9f3+/3Hu9XrkvLi7+8Xc6Ddz4EEj4EEj4EEj4EEj4EEj4EEj4EKg3GAy6\nPqPzAxhfX758Kfem39sfHByU+40bN8p9d3e33CcmJsp9DAz9QwY3PgQSPgQSPgQSPgQSPgQSPgQS\nPgTye3xG6tOnT+Xe9E7fZGpqqtxPwTv9X3HjQyDhQyDhQyDhQyDhQyDhQyDhQyDv+HTqx48f5b62\nttbp+UtLS51+/rhy40Mg4UMg4UMg4UMg4UMg4UMg4UMg7/h0anV1tdzfvn3b6vPv3r1b7ouLi60+\n/7Ry40Mg4UMg4UMg4UMg4UMg4UMg4UMg7/i00vR7+3fv3nV6/sOHD8v9/PnznZ4/rtz4EEj4EEj4\nEEj4EEj4EEj4EEj4EMg7PqWfP3+W+71798q97e/tr1+/Xu6zs7OtPj+VGx8CCR8CCR8CCR8CCR8C\nCR8CCR8CecentLe3V+47OzutPv/ixYvlvrm5We7nzp1rdX4qNz4EEj4EEj4EEj4EEj4EEj4EEj4E\n8o4f7v379+V++/btTs9fWloq97m5uU7PT+XGh0DCh0DCh0DCh0DCh0DCh0DCh0De8cO9evWq3I+P\nj8u91+uV+4MHD8p9Y2Oj3OmGGx8CCR8CCR8CCR8CCR8CCR8CCR8Ceccfc0dHR+X+7Nmzcl9fXy/3\npnf6y5cvl/ujR4/KndFw40Mg4UMg4UMg4UMg4UMg4UMg4UOg3mAw6PqMzg84zZp+L//8+fNyb/r/\n7ZtMTk6W++vXr8u93++3Op/Whv4hhhsfAgkfAgkfAgkfAgkfAgkfAgkfAnnHH7GXL1+W+507d8r9\n+/fvrc6/dOlSub9586bcr1271up8OucdH/hN+BBI+BBI+BBI+BBI+BBI+BDIO37Hmt7Zb926Ve4f\nP35sdf78/Hy5v3jxotxnZmZanc/IeccHfhM+BBI+BBI+BBI+BBI+BBI+BPKO39Lnz5/LfXl5udzb\nvtM3+fr1a7k3/R6fsecdH/hN+BBI+BBI+BBI+BBI+BBI+BDozKi/wLjb3Nws967f6Z88eVLuFy5c\n6PR8xpMbHwIJHwIJHwIJHwIJHwIJHwIJHwJ5x2/w9OnTct/e3j6hbzJcv98v97Nnz57QN2GcuPEh\nkPAhkPAhkPAhkPAhkPAhkPAhkHf8Bt++fSv3w8PDVp9/9erVcn/8+HG5r6ystDqfTG58CCR8CCR8\nCCR8CCR8CCR8CCR8COQdv8HCwkK5N/0e/8qVK+W+u7tb7tPT0+UOf8OND4GED4GED4GED4GED4GE\nD4GED4F6g8Gg6zM6PwD4T71h/+jGh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DC\nh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0Bn\nTuCMof8/NzA6bnwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwIJHwI\nJHwIJHwIJHwIJHwI9AsWPqhsLBJ92gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c307fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABRdJREFUeJzt3L1qlVkUgOHJaBPxBwxoYSEW1iKIXcrcgtiJgmBrE7Aw\nhV5BChsbwVqw8SYsvAglYKEWRiws5NgOzJktTnK+k5z3ecoswreal1Vs49psNvsLaPl72QsA0xM+\nBAkfgoQPQcKHIOFDkPAh6OQE3/APBWB51ub90MWHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ\n8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4E\nCR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgSdXPYCrLanT58O5zs7O8P5+vr6cL67uzuc37p1azg/d+7c\ncL6qXHwIEj4ECR+ChA9Bwocg4UOQ8CFobTabLfobC/8Ay/Ply5fh/Pr168P53t7egb5/4cKF4fzt\n27fD+eXLlw/0/WNgbd4PXXwIEj4ECR+ChA9Bwocg4UOQ8CHI3+NzIC9fvhzOD/pO/zt37twZzgPv\n9P+Liw9Bwocg4UOQ8CFI+BAkfAgSPgR5x2fozZs3w/n29vZEm3CYXHwIEj4ECR+ChA9Bwocg4UOQ\n8CHIOz5DHz9+HM5//vy50O+fOXNmOH/w4MFCv7+qXHwIEj4ECR+ChA9Bwocg4UOQ8CHIOz5DOzs7\nS/3+7du3h/MrV65MtMlqcfEhSPgQJHwIEj4ECR+ChA9Bwocg7/gr7sOHD8P5tWvXhvP9/f3DXOeP\nbW1tLfX7q8rFhyDhQ5DwIUj4ECR8CBI+BAkfgrzjr7jPnz8P51+/fp1ok/lu3LgxnG9ubk60SYuL\nD0HChyDhQ5DwIUj4ECR8CBI+BHnHX3GPHj1a9gpD9+7dG84vXrw40SYtLj4ECR+ChA9Bwocg4UOQ\n8CFI+BDkHf+Yu3r16nC+t7c30SbzPXz4cDi/f//+RJvwTy4+BAkfgoQPQcKHIOFDkPAhSPgQ5B3/\niPv27dtw/unTp+H8x48fh7nOv5w4cWI4/93f0//u91kMFx+ChA9Bwocg4UOQ8CFI+BAkfAjyjn/E\nPXnyZDjf39+faJP57t69O5xvb29PtAl/wsWHIOFDkPAhSPgQJHwIEj4ECR+CvOMv2ffv34fz9+/f\nT7TJfFtbW8P57u7uRJtwmFx8CBI+BAkfgoQPQcKHIOFDkPAhyDv+kj1+/Hg4f/Xq1USbzLexsTGc\nr6+vT7QJh8nFhyDhQ5DwIUj4ECR8CBI+BAkfgrzjL9m7d++W+v3Nzc3h/Pnz5xNtwpRcfAgSPgQJ\nH4KED0HChyDhQ5DwIcg7/oq7dOnScP769evh/PTp04e5DkeEiw9Bwocg4UOQ8CFI+BAkfAgSPgR5\nx19xp06dGs7Pnz8/0SYcJS4+BAkfgoQPQcKHIOFDkPAhSPgQ5B1/xT179mzZK3AEufgQJHwIEj4E\nCR+ChA9Bwocg4UOQd/xjbmNjYzg/e/bsRJtwnLj4ECR8CBI+BAkfgoQPQcKHIOFDkHf8Y+7FixfD\n+c2bNyfahOPExYcg4UOQ8CFI+BAkfAgSPgQJH4LWZrPZor+x8A8A/2lt3g9dfAgSPgQJH4KED0HC\nhyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CHo5ATf\nmPv/egPL4+JDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5Dw\nIUj4ECR8CPoFy8tuug1Fjr8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c467f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "plot_digit(X_12[8000])\n",
    "print(y_12[8000])\n",
    "\n",
    "plot_digit(X_12[9345])\n",
    "print(y_12[9345])\n",
    "\n",
    "plot_digit(X_12[877])\n",
    "print(y_12[877])\n",
    "\n",
    "plot_digit(X_12[144])\n",
    "print(y_12[144])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14867, 784)\n",
      "(14867,)\n"
     ]
    }
   ],
   "source": [
    "print(X_12.shape)\n",
    "print(y_12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our reduced dataset how many 1 and 2 do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 1: 7877\n",
      "number of 2: 6990\n"
     ]
    }
   ],
   "source": [
    "print(\"number of 1:\", np.count_nonzero(y_12 == 1))\n",
    "print(\"number of 2:\", np.count_nonzero(y_12 == 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle the elements and create a train and a test set. Altough it would be useful we will not do here a stratified sampling, prefering a simpler solution since the main point of this notebook is the complete implementation of logistic regression from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train is (11893, 784)\n",
      "Shape of X_test is (2974, 784)\n",
      "Shape of y_train is (11893,)\n",
      "Shape of y_test is (2974,)\n"
     ]
    }
   ],
   "source": [
    "shuffle_index = np.random.permutation(X_12.shape[0])\n",
    "X_12_shuffled, y_12_shuffled = X_12[shuffle_index], y_12[shuffle_index]\n",
    "\n",
    "train_proportion = 0.8\n",
    "train_test_cut = int(len(X_12)*train_proportion)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    X_12_shuffled[:train_test_cut], \\\n",
    "    X_12_shuffled[train_test_cut:], \\\n",
    "    y_12_shuffled[:train_test_cut], \\\n",
    "    y_12_shuffled[train_test_cut:]\n",
    "    \n",
    "print(\"Shape of X_train is\", X_train.shape)\n",
    "print(\"Shape of X_test is\", X_test.shape)\n",
    "print(\"Shape of y_train is\", y_train.shape)\n",
    "print(\"Shape of y_test is\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the proportions of 1 and 2 in our training and test set. In our original set we had the proportion of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.12689556509299"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_12 == 1) / np.count_nonzero(y_12 == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our training and test set we have the proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1139353003910415\n",
      "1.1803519061583578\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(y_train == 1) / np.count_nonzero(y_train == 2))\n",
    "print(np.count_nonzero(y_test == 1) / np.count_nonzero(y_test == 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are pretty close to the same proportion in our original dataset. Note that in this case is not so importnat since our training set is not so skewed, but normally you would have to do a stratified sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalise our data. The pixel will have a value between 0 and 255 (gray values). Let's normalise the value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_normalised = X_train/255.0\n",
    "X_test_normalised = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we need features along the rows, and training cases along the columns. So let's reshape our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 11893)\n",
      "(1, 11893)\n",
      "(784, 2974)\n",
      "(1, 2974)\n",
      "The training dataset has dimensions equal to 11893\n",
      "The test set has dimensions equal to 2974\n"
     ]
    }
   ],
   "source": [
    "X_train_tr = X_train_normalised.transpose()\n",
    "y_train_tr = y_train.reshape(1,y_train.shape[0])\n",
    "X_test_tr = X_test_normalised.transpose()\n",
    "y_test_tr = y_test.reshape(1,y_test.shape[0])\n",
    "\n",
    "print(X_train_tr.shape)\n",
    "print(y_train_tr.shape)\n",
    "print(X_test_tr.shape)\n",
    "print(y_test_tr.shape)\n",
    "\n",
    "dim_train = X_train_tr.shape[1]\n",
    "dim_test = X_test_tr.shape[1]\n",
    "\n",
    "print(\"The training dataset has dimensions equal to\", dim_train)\n",
    "print(\"The test set has dimensions equal to\", dim_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to rescale our lables. Remember we will compare them in the cost function with 0 and 1 (proabilities) and therefore our class labels must be 0 and 1, not 1 and 2. So the following step take care of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_shifted = y_train_tr - 1\n",
    "y_test_shifted = y_test_tr - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABIJJREFUeJzt3cFNI0kYgNFlNVlg5wEiD4jDnjiAOLDzwM7DJg7vgeuo\nWitP28D33pFS0335VIe/q31zOp3+AVr+vfYDAJcnfAgSPgQJH4KED0HChyDhQ9CvC9zDiwJwPTd/\n+qMdH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg\n4UOQ8CFI+BB0ic9rc0Xr9fqs619eXv7Sk/CV2PEhSPgQJHwIEj4ECR+ChA9Bwoegm9Np9l+x9jPZ\nM3p8fByub7fbWe///v4+XL+/v5/1/kzyM9nAJ+FDkPAhSPgQJHwIEj4ECR+CnMf/4jabzXB97jn9\nlMPhMFw3x/+a7PgQJHwIEj4ECR+ChA9Bwocg4UOQOf6VTc3pn56ezvr/b29vw/XlcnnW/ff7/XB9\n6nsBXIcdH4KED0HChyDhQ5DwIUj4ECR8CPJd/ZlNnVd/eHg46/rVajVcP/f37aeu//3793Ddd/ev\nznf1gU/ChyDhQ5DwIUj4ECR8CBI+BDmPP7OpOfe15/RTFovFWdfvdrvhujn+ddjxIUj4ECR8CBI+\nBAkfgoQPQcKHIHP8mU3N4afWv/uce+q7+1yHHR+ChA9Bwocg4UOQ8CFI+BAkfAgyx5/Zd5/D8zPZ\n8SFI+BAkfAgSPgQJH4KED0HChyBzfIaOx+O1H4EZ2PEhSPgQJHwIEj4ECR+ChA9Bwocgc3yGfBf/\nZ7LjQ5DwIUj4ECR8CBI+BAkfgoQPQeb4DN3d3Q3Xt9vthZ6Ev8mOD0HChyDhQ5DwIUj4ECR8CBI+\nBJnjM+Q8/s9kx4cg4UOQ8CFI+BAkfAgSPgQJH4LM8RlyHv9nsuNDkPAhSPgQJHwIEj4ECR+ChA9B\n5vgMOY//M9nxIUj4ECR8CBI+BAkfgoQPQcKHIHN8hhaLxbUfgRnY8SFI+BAkfAgSPgQJH4KED0HC\nhyBzfIamvqs/xXf3vyY7PgQJH4KED0HChyDhQ5DwIUj4EGSOz6zOfQ+AedjxIUj4ECR8CBI+BAkf\ngoQPQcKHIHP8L2632w3Xp757v1wuh+ubzWa4vt/vh+tTVqvVWdczDzs+BAkfgoQPQcKHIOFDkPAh\nSPgQdHM6nea+x+w3+M7W6/Vw/fX19UJPMo+p9wgOh8NZ/3/qvP/Hx8dZ10+95/AN3Pzpj3Z8CBI+\nBAkfgoQPQcKHIOFDkPAhyHn8mU3NqY/H43D9+fl5uH7ueflru729Ha5PvQcwZer66vcC7PgQJHwI\nEj4ECR+ChA9Bwocg4UOQ8/jwszmPD3wSPgQJH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQPQcKH\nIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UOQ8CFI+BAkfAgSPgQJH4KED0HChyDhQ5DwIUj4ECR8\nCBI+BAkfgoQPQcKHIOFDkPAh6NcF7nFzgXsA/4MdH4KED0HChyDhQ5DwIUj4ECR8CBI+BAkfgoQP\nQcKHIOFDkPAhSPgQJHwIEj4ECR+ChA9Bwocg4UPQf0DOgrS+G9l1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1191eed30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEj4EEj4EEj4EEj4EEj4EEj4EEj4EOi/Im4Z3HEvv7MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c379cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c233a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEj4EEj4EEj4EEj4EEj4EEj4EEj4EOgfyNAVu5X0A5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c841c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "plot_digit(X_train_tr[:,1005])\n",
    "print(y_train_shifted[:,1005])\n",
    "plot_digit(X_train_tr[:,1432])\n",
    "print(y_train_shifted[:,1432])\n",
    "plot_digit(X_train_tr[:,456])\n",
    "print(y_train_shifted[:,456])\n",
    "plot_digit(X_train_tr[:,567])\n",
    "print(y_train_shifted[:,567])\n",
    "\n",
    "Xtrain = X_train_tr\n",
    "ytrain = y_train_shifted\n",
    "Xtest = X_test_tr\n",
    "ytest = y_test_shifted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define a few helper function that we will put together to build a ```model()``` function that will train our model and give as a result a dictionary with the result. Where relevant we will put the mathematical formula we have used. As a reference you can check [this notebook on github](https://github.com/michelucci/Logistic-Regression-Explained/blob/master/Logistic%20Regression%20from%20scratch.ipynb) where I did a complete mathematical derivation of the necessary equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function\n",
    "\n",
    "This function will calculate the following formula given an input $z$\n",
    "\n",
    "$$ \\displaystyle\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Implement the sigmoid function\n",
    "\n",
    "    Arguments:\n",
    "    y -- a scalar (float)\n",
    "\n",
    "    Return:\n",
    "    s -- the sigmoid function evaluated on z (as in equation (1))\n",
    "    \"\"\"\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(dim):\n",
    "    \"\"\"\n",
    "    Initialise the weights and the bias to tensors of dimensions (dim,1) for w and\n",
    "    to 1 for b (a scalar)\n",
    "\n",
    "    Arguments:\n",
    "    dim -- a scalar (float)\n",
    "\n",
    "    Return:\n",
    "    w -- a matrix of dimensions (dim,1) containing all zero\n",
    "    b -- a scalar = 0\n",
    "    \"\"\"\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    \n",
    "    assert (w.shape == (dim,1))\n",
    "    assert (isinstance(b, float) or isinstance(b,int))\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function ```propagate(w,b,X,Y)``` will calculate \n",
    "\n",
    "$$\n",
    "\\displaystyle\n",
    "\\frac{\\partial \\mathscr{L} (a,y)}{\\partial w_j} = \\frac{1}{m} X (A-Y)^T\n",
    "\\tag{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\displaystyle\n",
    "\\frac{\\partial \\mathscr{L} (a,y)}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m}(A_i-Y_i) \n",
    "\\tag{3}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\displaystyle\n",
    "J(w,b) = \\frac{1}{m} \\sum_{i=1}^{m} \\mathscr{L} (a^{(i)},y^{(i)})\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "given\n",
    "$$\n",
    "\\mathscr{L} (a,y) = -\\left[ y \\log a + (1-y) \\log (1-a) \\right]\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "Our inputs are the weight $w \\in \\mathbb{R}^{n_x \\times 1}$ ($n_x$ number of features), $b \\in \\mathbb{R}$, $X \\in \\mathbb{R}^{n_x \\times m}$, $Y \\in \\mathbb{R}^{1 \\times m}$, $m$ is the number of training cases we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px, 1) (our case 784,1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if class 1, 1 if class 2) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    z = np.dot(w.T,X)+b\n",
    "    A = sigmoid(z)\n",
    "    cost = -1.0/m*np.sum(Y*np.log(A)+(1.0-Y)*np.log(1.0-A))\n",
    "    \n",
    "    dw = 1.0/m*np.dot(X, (A-Y).T)\n",
    "    db = 1.0/m*np.sum(A-Y)\n",
    "    \n",
    "    assert (dw.shape == w.shape)\n",
    "    assert (db.dtype == float)\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    assert (cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw, \n",
    "             \"db\":db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function actually perform the gradient descent algorithm. It does a loop modifying at each iterations the weigths and the bias according to (for an explanation of notation please refer to [this notebook](http://localhost:8888/notebooks/Documents/Data%20Science/Projects/Logistic-Regression-Explained/Logistic%20Regression%20from%20scratch.ipynb#).\n",
    "\n",
    "$$\\displaystyle\n",
    "w_{[n+1]} = w_{[n]}-\\alpha \\frac{1}{m} X (A-Y)^T\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\displaystyle\n",
    "b_{[n+1]} = b_{[n]}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m}(A_i-Y_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (n_x, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (n_x, m)\n",
    "    Y -- true \"label\" vector (containing 0 if class 1, 1 if class 2), of shape (1, m)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost (iteration %i) = %f\" %(i, cost))\n",
    "            \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    params = {\"w\": w, \"b\": b}\n",
    "        \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ```predict()``` create a matrix of dimensions $(1,m)$ that contains the predictions of the model given the input $w$, $b$ and $X$. Each prediction is assigned to class 1 if $\\sigma(w^T X+b) > 0.5$ and to class 2 if $\\sigma(w^T X+b) \\leq 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict (w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 \n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (n_x, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (n_x, m)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) \n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    \n",
    "    A = sigmoid (np.dot(w.T, X)+b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        if (A[:,i] > 0.5): \n",
    "            Y_prediction[:, i] = 1\n",
    "        elif (A[:,i] <= 0.5):\n",
    "            Y_prediction[:, i] = 0\n",
    "            \n",
    "    assert (Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the ```model()``` function that will put everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model (X_train, Y_train, X_test, Y_test, num_iterations = 1000, learning_rate = 0.5, print_cost = False):\n",
    "    \n",
    "    w, b = initialize(X_train.shape[0])\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict (w, b, X_test)\n",
    "    Y_prediction_train = predict (w, b, X_train)\n",
    "    \n",
    "    train_accuracy = 100.0 - np.mean(np.abs(Y_prediction_train-Y_train)*100.0)\n",
    "    test_accuracy = 100.0 - np.mean(np.abs(Y_prediction_test-Y_test)*100.0)\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "        \"Y_prediction_test\": Y_prediction_test,\n",
    "        \"Y_prediction_train\": Y_prediction_train,\n",
    "         \"w\": w,\n",
    "         \"b\": b,\n",
    "         \"learning_rate\": learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    print (\"Accuarcy Test: \",  test_accuracy)\n",
    "    print (\"Accuracy Train: \", train_accuracy)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of the model\n",
    "\n",
    "Let's test our model on our datasets containing only the digits 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (iteration 0) = 0.693147\n",
      "Cost (iteration 100) = 0.109078\n",
      "Cost (iteration 200) = 0.079466\n",
      "Cost (iteration 300) = 0.067267\n",
      "Cost (iteration 400) = 0.060286\n",
      "Cost (iteration 500) = 0.055634\n",
      "Cost (iteration 600) = 0.052246\n",
      "Cost (iteration 700) = 0.049633\n",
      "Cost (iteration 800) = 0.047536\n",
      "Cost (iteration 900) = 0.045801\n",
      "Cost (iteration 1000) = 0.044333\n",
      "Cost (iteration 1100) = 0.043070\n",
      "Cost (iteration 1200) = 0.041967\n",
      "Cost (iteration 1300) = 0.040992\n",
      "Cost (iteration 1400) = 0.040123\n",
      "Cost (iteration 1500) = 0.039340\n",
      "Cost (iteration 1600) = 0.038631\n",
      "Cost (iteration 1700) = 0.037985\n",
      "Cost (iteration 1800) = 0.037393\n",
      "Cost (iteration 1900) = 0.036847\n",
      "Cost (iteration 2000) = 0.036342\n",
      "Cost (iteration 2100) = 0.035873\n",
      "Cost (iteration 2200) = 0.035435\n",
      "Cost (iteration 2300) = 0.035027\n",
      "Cost (iteration 2400) = 0.034643\n",
      "Cost (iteration 2500) = 0.034282\n",
      "Cost (iteration 2600) = 0.033942\n",
      "Cost (iteration 2700) = 0.033621\n",
      "Cost (iteration 2800) = 0.033317\n",
      "Cost (iteration 2900) = 0.033028\n",
      "Cost (iteration 3000) = 0.032754\n",
      "Cost (iteration 3100) = 0.032492\n",
      "Cost (iteration 3200) = 0.032243\n",
      "Cost (iteration 3300) = 0.032005\n",
      "Cost (iteration 3400) = 0.031777\n",
      "Cost (iteration 3500) = 0.031559\n",
      "Cost (iteration 3600) = 0.031350\n",
      "Cost (iteration 3700) = 0.031148\n",
      "Cost (iteration 3800) = 0.030955\n",
      "Cost (iteration 3900) = 0.030769\n",
      "Accuarcy Test:  99.092131809\n",
      "Accuracy Train:  99.1003111074\n"
     ]
    }
   ],
   "source": [
    "d = model (Xtrain, \n",
    "           ytrain, \n",
    "           Xtest, \n",
    "           ytest, \n",
    "           num_iterations = 4000, \n",
    "           learning_rate = 0.05, \n",
    "           print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get an accuracy of roughly 99%. Pretty good. \n",
    "Let's see how the confusion matrix look like. To make it easier let's use the ```confusion_matrix()``` function from the package ```sklearn.metrics```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1596,   14],\n",
       "       [  13, 1351]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = d[\"Y_prediction_test\"]\n",
    "ypred_ravel = ypred.ravel()\n",
    "ytest_ravel = ytest.ravel()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix (ytest_ravel, ypred_ravel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this works really well since 1 and 2 are easy to distinguish. If you check all the digits you will see that (for example) two of the digits that are the most difficult (relatively) to distinguish are 3 and 5. The same notebook can be run with different digits to check this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function vs. number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the cost function decrease with the number of iterations. We have the value of the cost function every $100$ iterations so we can easily plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEfCAYAAACTTLsLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZnl5v8B5Wnhhxn9oZ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c243a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d[\"costs\"])\n",
    "plt.xlim([1,40])\n",
    "plt.ylim([0,0.12])\n",
    "plt.title(\"Cost Function\",fontsize = 15)\n",
    "plt.xlabel(\"Number of iterations x 100\", fontsize = 14)\n",
    "plt.ylabel(\"$J(w,b)$\", fontsize = 17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, here is the code to see how easy it is in comparison to do the same with the sklearn library... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11893, 784)\n",
      "(11893,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = Xtrain.T\n",
    "YY = ytrain.T.ravel()\n",
    "\n",
    "logistic.fit(XX,YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957958462961406"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(XX,YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is calculated as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957958462961406"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(logistic.predict(XX) == YY) / len(XX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
